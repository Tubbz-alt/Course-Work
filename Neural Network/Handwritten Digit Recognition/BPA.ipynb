{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Libararies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mnist\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back Propogation Algorithm\n",
    "## ReLU is used as Activation Function\n",
    "## Total Data -> 120k Train and Test Data\n",
    "## Weights are Randomly Assigned between 0 and 1.\n",
    "## Learning Rate is given by User.\n",
    "## Number of Epochs are given by User.\n",
    "## Manually Calculated Number of Nodes in Each Layer.\n",
    "## MNIST Dataset is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BPA:\n",
    "    def __init__(self, num_nodes_in_layers, num_epochs, learning_rate):\n",
    "        self.num_nodes_in_layers = num_nodes_in_layers\n",
    "        self.num_epochs = num_epochs\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # build the network\n",
    "        #         w1/b1    w2/b2   \n",
    "        #784(inputs) ---> 20 ---> 10(output)\n",
    "        #         x     z1  a1  z2  a2=y\n",
    "        self.weight1 = np.random.normal(0, 1, [self.num_nodes_in_layers[0], self.num_nodes_in_layers[1]])\n",
    "        self.bias1 = np.zeros((1, self.num_nodes_in_layers[1]))\n",
    "        self.weight2 = np.random.normal(0, 1, [self.num_nodes_in_layers[1], self.num_nodes_in_layers[2]])\n",
    "        self.bias2 = np.zeros((1, self.num_nodes_in_layers[2]))\n",
    "    '''\n",
    "    def plot(self, x, y, epoch ):\n",
    "        plt.scatter( x, y, label = 'Error Rate',color = 'r')\n",
    "        plt.xlabel('Error')\n",
    "        plt.ylabel('Iteration')\n",
    "        plt.title('Epoch\\t:\\t' + str(epoch) + 'Rate')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    '''    \n",
    "        \n",
    "    #using Relu\n",
    "    def relu(self, inputs):\n",
    "        return np.maximum(inputs, 0)\n",
    "    \n",
    "    def softmax(self, inputs):\n",
    "        exp = np.exp(inputs)\n",
    "        return exp/np.sum(exp, axis = 1, keepdims = True)\n",
    "\n",
    "    def train(self, inputs, labels):\n",
    "        for epoch in range(self.num_epochs): # training begin\n",
    "            i = 0\n",
    "            #List = []\n",
    "            #iterationList = []\n",
    "            while i < len(inputs):\n",
    "\n",
    "                # batch input\n",
    "                inputs_batch = inputs[i:i + 1]\n",
    "                labels_batch = labels[i:i + 1]\n",
    "                \n",
    "                # forward pass\n",
    "                z1 = np.dot(inputs_batch, self.weight1) + self.bias1\n",
    "                a1 = self.relu(z1)\n",
    "                z2 = np.dot(a1, self.weight2) + self.bias2\n",
    "                y = self.softmax(z2)\n",
    "                \n",
    "            \n",
    "                # backward pass\n",
    "                delta_y = (y - labels_batch) / y.shape[0]\n",
    "                delta_hidden_layer = np.dot(delta_y, self.weight2.T) \n",
    "                delta_hidden_layer[a1 <= 0] = 0 # derivatives of relu\n",
    "                '''\n",
    "                #Appending Error and Iteration Number\n",
    "                List.append(y)\n",
    "                iterationList.append(i + 1)\n",
    "                '''\n",
    "                # backpropagation\n",
    "                weight2_gradient = np.dot(a1.T, delta_y) # forward * backward\n",
    "                bias2_gradient = np.sum(delta_y, axis = 0, keepdims = True)\n",
    "            \n",
    "                weight1_gradient = np.dot(inputs_batch.T, delta_hidden_layer)\n",
    "                bias1_gradient = np.sum(delta_hidden_layer, axis = 0, keepdims = True)\n",
    "\n",
    "                weight2_gradient += 0.01 * self.weight2\n",
    "                weight1_gradient += 0.01 * self.weight1\n",
    "\n",
    "                # stochastic gradient descent\n",
    "                self.weight1 -= self.learning_rate * weight1_gradient #update weight and bias\n",
    "                self.bias1 -= self.learning_rate * bias1_gradient\n",
    "                self.weight2 -= self.learning_rate * weight2_gradient\n",
    "                self.bias2 -= self.learning_rate * bias2_gradient\n",
    "                #print('Epoch\\t:\\t', epoch , '/' , self.num_epochs , '\\tIterations\\t:\\t', i)\n",
    "                i += 1\n",
    "            #self.plot(List, iterationList, epoch)\n",
    "            print('Epoch\\t:\\t', epoch , '/' , self.num_epochs , '\\tIterations\\t:\\t', i)\n",
    "            \n",
    "    def test(self, inputs, labels):\n",
    "        input_layer = np.dot(inputs, self.weight1)\n",
    "        hidden_layer = self.relu(input_layer + self.bias1)\n",
    "        scores = np.dot(hidden_layer, self.weight2) + self.bias2\n",
    "        probs = self.softmax(scores)\n",
    "        acc = float(np.sum(np.argmax(probs, 1) == labels)) / float(len(labels))\n",
    "        print('\\nTest accuracy\\t:\\t', acc*100)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data is normalized before it's used.\n",
    "## Accuracy is printed after Testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training!\n",
      "Epoch\t:\t 0 / 20 \tIterations\t:\t 60000\n",
      "Epoch\t:\t 1 / 20 \tIterations\t:\t 60000\n",
      "Epoch\t:\t 2 / 20 \tIterations\t:\t 60000\n",
      "Epoch\t:\t 3 / 20 \tIterations\t:\t 60000\n",
      "Epoch\t:\t 4 / 20 \tIterations\t:\t 60000\n",
      "Epoch\t:\t 5 / 20 \tIterations\t:\t 60000\n",
      "Epoch\t:\t 6 / 20 \tIterations\t:\t 60000\n",
      "Epoch\t:\t 7 / 20 \tIterations\t:\t 60000\n",
      "Epoch\t:\t 8 / 20 \tIterations\t:\t 60000\n",
      "Epoch\t:\t 9 / 20 \tIterations\t:\t 60000\n",
      "Epoch\t:\t 10 / 20 \tIterations\t:\t 60000\n",
      "Epoch\t:\t 11 / 20 \tIterations\t:\t 60000\n",
      "Epoch\t:\t 12 / 20 \tIterations\t:\t 60000\n",
      "Epoch\t:\t 13 / 20 \tIterations\t:\t 60000\n",
      "Epoch\t:\t 14 / 20 \tIterations\t:\t 60000\n",
      "Epoch\t:\t 15 / 20 \tIterations\t:\t 60000\n",
      "Epoch\t:\t 16 / 20 \tIterations\t:\t 60000\n",
      "Epoch\t:\t 17 / 20 \tIterations\t:\t 60000\n",
      "Epoch\t:\t 18 / 20 \tIterations\t:\t 60000\n",
      "Epoch\t:\t 19 / 20 \tIterations\t:\t 60000\n",
      "Testing!\n",
      "\n",
      "Test accuracy\t:\t 86.11999999999999\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# load data\n",
    "num_classes = 10\n",
    "train_images = mnist.train_images() #[60000, 28, 28]\n",
    "train_labels = mnist.train_labels()\n",
    "test_images = mnist.test_images()\n",
    "test_labels = mnist.test_labels()\n",
    "\n",
    "print(\"Training!\")\n",
    "\n",
    "# data processing\n",
    "X_train = train_images.reshape(train_images.shape[0], train_images.shape[1]*train_images.shape[2]).astype('float32') #flatten 28x28 to 784x1 vectors, [60000, 784]\n",
    "x_train = X_train / 255 #normalization\n",
    "y_train = np.eye(num_classes)[train_labels] #convert label to one-hot\n",
    "\n",
    "X_test = test_images.reshape(test_images.shape[0], test_images.shape[1]*test_images.shape[2]).astype('float32') #flatten 28x28 to 784x1 vectors, [60000, 784]\n",
    "x_test = X_test / 255 #normalization\n",
    "y_test = test_labels\n",
    "\n",
    "obj = BPA(\n",
    "                 num_nodes_in_layers = [784, 20, num_classes], \n",
    "                 num_epochs = 20,\n",
    "                 learning_rate = 0.0001\n",
    "             )\n",
    "\n",
    "obj.train(x_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Testing!\")\n",
    "obj.test(x_test, y_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
